{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrvrWyxQgtLqLjg0bwEnLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddkryptonite/-semiconductor-market-data-aws-pipeline/blob/main/DataScrappingPythonPowerBI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmPQw7Yom8A_"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import pandas as pd\n",
        "import os\n",
        "import boto3\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AWS S3 Setup\n",
        "S3_BUCKET = \"your-s3-bucket-name\"\n",
        "S3_FILE_NAME = \"semiconductor_scraped_data.csv\""
      ],
      "metadata": {
        "id": "ERl0AurkRxhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize S3 client\n",
        "s3 = boto3.client(\"s3\")"
      ],
      "metadata": {
        "id": "4zUwC7AeSG-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install boto3"
      ],
      "metadata": {
        "id": "4AD8TkpsRQ1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def scrape_data():\n",
        "    url = \"https://en.wikipedia.org/wiki/Semiconductor_industry#:~:text=The%20global%20semiconductor%20industry%20is,significant%20presence%20in%20the%20field.&text=Unique%20features%20of%20the%20industry,cyclical%20pattern%20with%20high%20volatility.\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        print(\"Data retrieved successfully!\")\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
        "\n",
        "\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    table = soup.find_all('table', class_ = 'wikitable')[0]\n",
        "\n",
        "    header_row = table.find(\"tr\")\n",
        "\n",
        "    table_titles = header_row.find_all('th')\n",
        "\n",
        "    complete_table_titles = [title.text.strip() for title in table_titles]\n",
        "    #print( complete_table_titles)\n",
        "\n",
        "    #soup.find('div')\n",
        "    #print(soup.find_all('table', class_ = 'wikitable')[0])\n",
        "#scrape_data()\n",
        "\n",
        "    data = []\n",
        "    for row in table.find_all(\"tr\")[1:]:\n",
        "        cols = row.find_all([\"th\", \"td\"])\n",
        "        data.append([col.text.strip() for col in cols])\n",
        "\n",
        "    #print(complete_table_titles)\n",
        "    #print(data)\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(data, columns=complete_table_titles)\n",
        "\n",
        "    df = df.drop(columns = 'Ref.')          # Remove missing values\n",
        "    df.drop_duplicates(inplace=True) # Remove duplicate rows\n",
        "    #df['Year'] = df['Year'].astype(int)  # Convert to Integer\n",
        "    df['Year'] = pd.to_datetime(df['Year'])  # Convert to Date\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def upload_to_s3(df):\n",
        "    #Uploads DataFrame to S3 as a CSV file\n",
        "    csv_buffer = io.StringIO()\n",
        "    df.to_csv(csv_buffer, index=False)\n",
        "\n",
        "    s3.put_object(\n",
        "        Bucket=S3_BUCKET,\n",
        "        Key=S3_FILE_NAME,\n",
        "        Body=csv_buffer.getvalue()\n",
        "    )\n",
        "\n",
        "    print(f\"Data uploaded to s3://{S3_BUCKET}/{S3_FILE_NAME}\")\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    df = scrape_data()\n",
        "    if df is not None:\n",
        "      upload_to_s3(df)\n",
        "    return {\"statusCode\": 200, \"body\": \"ETL Pipeline Completed\"}\n"
      ],
      "metadata": {
        "id": "8iI0lqffnvbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}